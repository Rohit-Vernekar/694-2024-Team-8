{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-24 17:55:48,493 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts\n",
      "2024-04-24 17:55:48,494 - apscheduler.scheduler - INFO - Added job \"Cache.save_to_disk\" to job store \"default\"\n",
      "2024-04-24 17:55:48,494 - apscheduler.scheduler - INFO - Scheduler started\n",
      "2024-04-24 17:55:48,495 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:55:48,498 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 17:56:48.492165-04:00 (in 59.994001 seconds)\n",
      "2024-04-24 17:55:48,500 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts\n",
      "2024-04-24 17:55:48,501 - apscheduler.scheduler - INFO - Added job \"Cache.save_to_disk\" to job store \"default\"\n",
      "2024-04-24 17:55:48,501 - apscheduler.scheduler - INFO - Scheduler started\n",
      "2024-04-24 17:55:48,502 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:55:48,519 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 17:56:48.500163-04:00 (in 59.980860 seconds)\n",
      "2024-04-24 17:55:48,522 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts\n",
      "2024-04-24 17:55:48,523 - apscheduler.scheduler - INFO - Added job \"TrendingHashtags.save_trending_hashtags\" to job store \"default\"\n",
      "2024-04-24 17:55:48,524 - apscheduler.scheduler - INFO - Scheduler started\n",
      "2024-04-24 17:55:48,525 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:55:48,528 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 17:56:48.522608-04:00 (in 59.994007 seconds)\n"
     ]
    }
   ],
   "source": [
    "import src.tweet_data_processor as tdp\n",
    "import src.twitter_queries as tq\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "search_app = tq.TwitterQueries()\n",
    "dbs = tdp.TweetDataProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75377 users in MySQL\n"
     ]
    }
   ],
   "source": [
    "cursor = dbs.mysql_conn.cursor(buffered=True)\n",
    "cursor.execute('SELECT count(*) as n_users FROM twitter.users')\n",
    "fname = cursor.fetchone()[0]\n",
    "print(fname,'users in MySQL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6008 hashtags in MySQL\n"
     ]
    }
   ],
   "source": [
    "cursor.execute('SELECT count(distinct hashtag) as n_users FROM twitter.hashtags')\n",
    "fname = cursor.fetchone()[0]\n",
    "print(fname,'hashtags in MySQL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86656 tweets in MongoDB\n"
     ]
    }
   ],
   "source": [
    "print(dbs.tweet_collection.count_documents({}),'tweets in MongoDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62744 relationships between users in Neo4J\n"
     ]
    }
   ],
   "source": [
    "res = dbs.neo4j_connection.execute_query(\"MATCH ()-[r]->() RETURN count(r) as n\")\n",
    "print(res.records[0][0],'relationships between users in Neo4J')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_experiments = 10000\n",
    "stats_sample = 1000\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT id_str FROM twitter.users\n",
    "ORDER BY RAND()\n",
    "LIMIT 5000\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "sample_users = cursor.fetchall()\n",
    "sample_users_list = [x[0] for x in sample_users]\n",
    "\n",
    "## for hashtags, focusing only on the ones with 1 twitter\n",
    "query = \"\"\"\n",
    "WITH tb as \n",
    "(SELECT hashtag\n",
    "FROM (SELECT hashtag, count(tweet_id) as n_tweet FROM twitter.hashtags\n",
    "GROUP BY 1\n",
    "HAVING n_tweet = 1) a)\n",
    "\n",
    "SELECT hashtag, tweet_id\n",
    "FROM twitter.hashtags a\n",
    "WHERE hashtag in (select hashtag from tb)\n",
    "ORDER BY RAND()\n",
    "LIMIT 3000\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "sample_hashtags = cursor.fetchall()\n",
    "sample_hashtags_list = [x[0] for x in sample_hashtags]\n",
    "tweets_hashtags_list = [x[1] for x in sample_hashtags]\n",
    "\n",
    "tweets = dbs.tweet_collection.aggregate([{ \"$sample\": { \"size\": 5000 } }])\n",
    "tweets_list = [i['id_str'] for i in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-24 17:56:48,506 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:56:48,506 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:56:48,508 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 17:57:48 EDT)\" (scheduled at 2024-04-24 17:56:48.500163-04:00)\n",
      "2024-04-24 17:56:48,508 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 17:57:48.500163-04:00 (in 59.992053 seconds)\n",
      "2024-04-24 17:56:48,513 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 17:57:48 EDT)\" (scheduled at 2024-04-24 17:56:48.492165-04:00)\n",
      "2024-04-24 17:56:48,513 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 17:57:48.492165-04:00 (in 59.979053 seconds)\n",
      "2024-04-24 17:56:48,513 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 17:57:48 EDT)\" executed successfully\n",
      "2024-04-24 17:56:48,541 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:56:48,555 - apscheduler.executors.default - INFO - Running job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 17:56:48 EDT)\" (scheduled at 2024-04-24 17:56:48.522608-04:00)\n",
      "2024-04-24 17:56:48,567 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 17:57:48.522608-04:00 (in 59.954870 seconds)\n",
      "2024-04-24 17:56:48,604 - apscheduler.executors.default - INFO - Job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 17:57:48 EDT)\" executed successfully\n",
      "2024-04-24 17:56:48,622 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 17:57:48 EDT)\" executed successfully\n",
      "2024-04-24 17:57:48,511 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:57:48,512 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 17:58:48.500163-04:00 (in 59.987209 seconds)\n",
      "2024-04-24 17:57:48,512 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 17:58:48 EDT)\" (scheduled at 2024-04-24 17:57:48.500163-04:00)\n",
      "2024-04-24 17:57:48,516 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 17:58:48 EDT)\" executed successfully\n",
      "2024-04-24 17:57:48,526 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:57:48,529 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 17:58:48.492165-04:00 (in 59.962505 seconds)\n",
      "2024-04-24 17:57:48,529 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 17:58:48 EDT)\" (scheduled at 2024-04-24 17:57:48.492165-04:00)\n",
      "2024-04-24 17:57:48,589 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:57:48,594 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 17:58:48 EDT)\" executed successfully\n",
      "2024-04-24 17:57:48,594 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 17:58:48.522608-04:00 (in 59.928017 seconds)\n",
      "2024-04-24 17:57:48,595 - apscheduler.executors.default - INFO - Running job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 17:58:48 EDT)\" (scheduled at 2024-04-24 17:57:48.522608-04:00)\n",
      "2024-04-24 17:57:48,598 - apscheduler.executors.default - INFO - Job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 17:58:48 EDT)\" executed successfully\n",
      "2024-04-24 17:58:48,508 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:58:48,508 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:58:48,511 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 17:59:48.500163-04:00 (in 59.988773 seconds)\n",
      "2024-04-24 17:58:48,510 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 17:59:48 EDT)\" (scheduled at 2024-04-24 17:58:48.492165-04:00)\n",
      "2024-04-24 17:58:48,509 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 17:59:48.492165-04:00 (in 59.982775 seconds)\n",
      "2024-04-24 17:58:48,511 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 17:59:48 EDT)\" (scheduled at 2024-04-24 17:58:48.500163-04:00)\n",
      "2024-04-24 17:58:48,538 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 17:59:48 EDT)\" executed successfully\n",
      "2024-04-24 17:58:48,538 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:58:48,553 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 17:59:48.522608-04:00 (in 59.968780 seconds)\n",
      "2024-04-24 17:58:48,553 - apscheduler.executors.default - INFO - Running job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 17:59:48 EDT)\" (scheduled at 2024-04-24 17:58:48.522608-04:00)\n",
      "2024-04-24 17:58:48,581 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 17:59:48 EDT)\" executed successfully\n",
      "2024-04-24 17:58:48,583 - apscheduler.executors.default - INFO - Job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 17:59:48 EDT)\" executed successfully\n",
      "2024-04-24 17:59:48,518 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:59:48,518 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:59:48,519 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:00:48.492165-04:00 (in 59.972530 seconds)\n",
      "2024-04-24 17:59:48,519 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:00:48 EDT)\" (scheduled at 2024-04-24 17:59:48.492165-04:00)\n",
      "2024-04-24 17:59:48,520 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:00:48.500163-04:00 (in 59.979529 seconds)\n",
      "2024-04-24 17:59:48,520 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:00:48 EDT)\" (scheduled at 2024-04-24 17:59:48.500163-04:00)\n",
      "2024-04-24 17:59:48,549 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 17:59:48,549 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:00:48 EDT)\" executed successfully\n",
      "2024-04-24 17:59:48,561 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:00:48.522608-04:00 (in 59.960780 seconds)\n",
      "2024-04-24 17:59:48,562 - apscheduler.executors.default - INFO - Running job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:00:48 EDT)\" (scheduled at 2024-04-24 17:59:48.522608-04:00)\n",
      "2024-04-24 17:59:48,592 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:00:48 EDT)\" executed successfully\n",
      "2024-04-24 17:59:48,631 - apscheduler.executors.default - INFO - Job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:00:48 EDT)\" executed successfully\n",
      "2024-04-24 18:00:48,499 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:00:48,500 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:01:48.492165-04:00 (in 59.992096 seconds)\n",
      "2024-04-24 18:00:48,501 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:01:48 EDT)\" (scheduled at 2024-04-24 18:00:48.492165-04:00)\n",
      "2024-04-24 18:00:48,522 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:00:48,539 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:01:48.500163-04:00 (in 59.960942 seconds)\n",
      "2024-04-24 18:00:48,557 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:01:48 EDT)\" (scheduled at 2024-04-24 18:00:48.500163-04:00)\n",
      "2024-04-24 18:00:48,574 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:01:48 EDT)\" executed successfully\n",
      "2024-04-24 18:00:48,574 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:00:48,577 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:01:48 EDT)\" executed successfully\n",
      "2024-04-24 18:00:48,578 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:01:48.522608-04:00 (in 59.944311 seconds)\n",
      "2024-04-24 18:00:48,579 - apscheduler.executors.default - INFO - Running job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:01:48 EDT)\" (scheduled at 2024-04-24 18:00:48.522608-04:00)\n",
      "2024-04-24 18:00:48,585 - apscheduler.executors.default - INFO - Job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:01:48 EDT)\" executed successfully\n"
     ]
    }
   ],
   "source": [
    "time_list_cache = []\n",
    "time_list_wo_cache = []\n",
    "\n",
    "for i in range(0,n_experiments):\n",
    "    number = random.randint(0, len(sample_hashtags_list)-1)\n",
    "    hashtag_id = sample_hashtags_list[number]\n",
    "    tweet_id = tweets_hashtags_list[number]\n",
    "    is_in_cache = search_app.tweet_cache.get(tweet_id) is not None\n",
    "    tic = time.perf_counter()\n",
    "    search_app.search_tweets_by_hashtag(hashtag_id)\n",
    "    toc = time.perf_counter()\n",
    "    if is_in_cache:\n",
    "        time_list_cache.append(toc-tic)\n",
    "    else:\n",
    "        time_list_wo_cache.append(toc-tic)\n",
    "    \n",
    "results = {\n",
    "    'with_cache':time_list_cache,\n",
    "    'without_cache':time_list_wo_cache\n",
    "}\n",
    "\n",
    "with open('hashtag_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without cache\n",
      "mean: 46.2792 ms\n",
      "std: 18.9015 ms\n",
      "With cache\n",
      "mean: 29.2719 ms\n",
      "std: 6.5254 ms\n"
     ]
    }
   ],
   "source": [
    "time_list_wo_cache = np.array(time_list_wo_cache)\n",
    "chosen_ids = random.sample(range(0,len(time_list_wo_cache)), stats_sample)\n",
    "print('Without cache')    \n",
    "print('mean:',f'{np.mean(time_list_wo_cache[chosen_ids])*1000:0.4f} ms')\n",
    "print('std:',f'{np.std(time_list_wo_cache[chosen_ids])*1000:0.4f} ms')\n",
    "time_list_cache = np.array(time_list_cache)\n",
    "chosen_ids = random.sample(range(0,len(time_list_cache)), stats_sample)\n",
    "print('With cache')  \n",
    "print('mean:',f'{np.mean(time_list_cache[chosen_ids])*1000:0.4f} ms')\n",
    "print('std:',f'{np.std(time_list_cache[chosen_ids])*1000:0.4f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-24 18:01:48,518 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:01:48,521 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:02:48.492165-04:00 (in 59.971156 seconds)\n",
      "2024-04-24 18:01:48,521 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:02:48 EDT)\" (scheduled at 2024-04-24 18:01:48.492165-04:00)\n",
      "2024-04-24 18:01:48,545 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:01:48,554 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:01:48,556 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:02:48.522608-04:00 (in 59.966081 seconds)\n",
      "2024-04-24 18:01:48,558 - apscheduler.executors.default - INFO - Running job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:02:48 EDT)\" (scheduled at 2024-04-24 18:01:48.522608-04:00)\n",
      "2024-04-24 18:01:48,580 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:02:48.500163-04:00 (in 59.920036 seconds)\n",
      "2024-04-24 18:01:48,583 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:02:48 EDT)\" (scheduled at 2024-04-24 18:01:48.500163-04:00)\n",
      "2024-04-24 18:01:48,627 - apscheduler.executors.default - INFO - Job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:02:48 EDT)\" executed successfully\n",
      "2024-04-24 18:01:48,628 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:02:48 EDT)\" executed successfully\n",
      "2024-04-24 18:01:48,706 - apscheduler.executors.default - ERROR - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:02:48 EDT)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sofia\\anaconda3\\Lib\\site-packages\\apscheduler\\executors\\base.py\", line 125, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sofia\\OneDrive\\Documents\\Rutgers\\DatabaseManagement\\Project\\Git_Master\\694-2024-Team-8\\src\\cache.py\", line 42, in save_to_disk\n",
      "    pickle.dump(self._data, fp)\n",
      "RuntimeError: dictionary changed size during iteration\n",
      "2024-04-24 18:02:48,510 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:02:48,511 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:03:48.492165-04:00 (in 59.980638 seconds)\n",
      "2024-04-24 18:02:48,511 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:03:48 EDT)\" (scheduled at 2024-04-24 18:02:48.492165-04:00)\n",
      "2024-04-24 18:02:48,567 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:02:48,577 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:03:48.500163-04:00 (in 59.922602 seconds)\n",
      "2024-04-24 18:02:48,592 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:02:48,592 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:03:48 EDT)\" (scheduled at 2024-04-24 18:02:48.500163-04:00)\n",
      "2024-04-24 18:02:48,606 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:03:48 EDT)\" executed successfully\n",
      "2024-04-24 18:02:48,606 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:03:48.522608-04:00 (in 59.916527 seconds)\n",
      "2024-04-24 18:02:48,635 - apscheduler.executors.default - INFO - Running job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:03:48 EDT)\" (scheduled at 2024-04-24 18:02:48.522608-04:00)\n",
      "2024-04-24 18:02:48,655 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:03:48 EDT)\" executed successfully\n",
      "2024-04-24 18:02:48,672 - apscheduler.executors.default - INFO - Job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:03:48 EDT)\" executed successfully\n",
      "2024-04-24 18:03:48,499 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:03:48,511 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:04:48.492165-04:00 (in 59.980772 seconds)\n",
      "2024-04-24 18:03:48,512 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:04:48 EDT)\" (scheduled at 2024-04-24 18:03:48.492165-04:00)\n",
      "2024-04-24 18:03:48,531 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:03:48,560 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:04:48.500163-04:00 (in 59.939661 seconds)\n",
      "2024-04-24 18:03:48,561 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:04:48 EDT)\" (scheduled at 2024-04-24 18:03:48.500163-04:00)\n",
      "2024-04-24 18:03:48,594 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:03:48,594 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:04:48 EDT)\" executed successfully\n",
      "2024-04-24 18:03:48,598 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:04:48.522608-04:00 (in 59.924299 seconds)\n",
      "2024-04-24 18:03:48,599 - apscheduler.executors.default - INFO - Running job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:04:48 EDT)\" (scheduled at 2024-04-24 18:03:48.522608-04:00)\n",
      "2024-04-24 18:03:48,603 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:04:48 EDT)\" executed successfully\n",
      "2024-04-24 18:03:48,606 - apscheduler.executors.default - INFO - Job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:04:48 EDT)\" executed successfully\n",
      "2024-04-24 18:04:48,506 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:04:48,507 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:05:48.492165-04:00 (in 59.984259 seconds)\n",
      "2024-04-24 18:04:48,508 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:05:48 EDT)\" (scheduled at 2024-04-24 18:04:48.492165-04:00)\n",
      "2024-04-24 18:04:48,511 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:04:48,513 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:05:48.500163-04:00 (in 59.986687 seconds)\n",
      "2024-04-24 18:04:48,514 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:05:48 EDT)\" (scheduled at 2024-04-24 18:04:48.500163-04:00)\n",
      "2024-04-24 18:04:48,544 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:04:48,555 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:05:48.522608-04:00 (in 59.967479 seconds)\n",
      "2024-04-24 18:04:48,555 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:05:48 EDT)\" executed successfully\n",
      "2024-04-24 18:04:48,555 - apscheduler.executors.default - INFO - Running job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:05:48 EDT)\" (scheduled at 2024-04-24 18:04:48.522608-04:00)\n",
      "2024-04-24 18:04:48,608 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:05:48 EDT)\" executed successfully\n",
      "2024-04-24 18:04:48,610 - apscheduler.executors.default - INFO - Job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:05:48 EDT)\" executed successfully\n",
      "2024-04-24 18:05:48,508 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:05:48,509 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:05:48,510 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:06:48.492165-04:00 (in 59.982162 seconds)\n",
      "2024-04-24 18:05:48,510 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:06:48 EDT)\" (scheduled at 2024-04-24 18:05:48.492165-04:00)\n",
      "2024-04-24 18:05:48,512 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:06:48.500163-04:00 (in 59.988161 seconds)\n",
      "2024-04-24 18:05:48,512 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:06:48 EDT)\" (scheduled at 2024-04-24 18:05:48.500163-04:00)\n",
      "2024-04-24 18:05:48,549 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:06:48 EDT)\" executed successfully\n",
      "2024-04-24 18:05:48,553 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:05:48,600 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:06:48 EDT)\" executed successfully\n",
      "2024-04-24 18:05:48,601 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:06:48.522608-04:00 (in 59.921179 seconds)\n",
      "2024-04-24 18:05:48,617 - apscheduler.executors.default - INFO - Running job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:06:48 EDT)\" (scheduled at 2024-04-24 18:05:48.522608-04:00)\n",
      "2024-04-24 18:05:48,622 - apscheduler.executors.default - INFO - Job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:06:48 EDT)\" executed successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "time_list_cache = []\n",
    "time_list_wo_cache = []\n",
    "\n",
    "for i in range(0,n_experiments):\n",
    "    number = random.randint(0, len(sample_users_list)-1)\n",
    "    user_id = sample_users_list[number]\n",
    "    is_in_cache = search_app.user_cache.get(user_id) is not None\n",
    "    tic = time.perf_counter()\n",
    "    search_app.get_user_data([user_id])\n",
    "    toc = time.perf_counter()\n",
    "    if is_in_cache:\n",
    "        time_list_cache.append(toc-tic)\n",
    "    else:\n",
    "        time_list_wo_cache.append(toc-tic)\n",
    "\n",
    "results = {\n",
    "    'with_cache':time_list_cache,\n",
    "    'without_cache':time_list_wo_cache\n",
    "}\n",
    "\n",
    "\n",
    "with open('user_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without cache\n",
      "mean: 28.4548 ms\n",
      "std: 4.9709 ms\n",
      "With cache\n",
      "mean: 13.9489 ms\n",
      "std: 3.0011 ms\n"
     ]
    }
   ],
   "source": [
    "time_list_wo_cache = np.array(time_list_wo_cache)\n",
    "chosen_ids = random.sample(range(0,len(time_list_wo_cache)), stats_sample)\n",
    "print('Without cache')    \n",
    "print('mean:',f'{np.mean(time_list_wo_cache[chosen_ids])*1000:0.4f} ms')\n",
    "print('std:',f'{np.std(time_list_wo_cache[chosen_ids])*1000:0.4f} ms')\n",
    "time_list_cache = np.array(time_list_cache)\n",
    "chosen_ids = random.sample(range(0,len(time_list_cache)), stats_sample)\n",
    "print('With cache')  \n",
    "print('mean:',f'{np.mean(time_list_cache[chosen_ids])*1000:0.4f} ms')\n",
    "print('std:',f'{np.std(time_list_cache[chosen_ids])*1000:0.4f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list_cache = []\n",
    "time_list_wo_cache = []\n",
    "\n",
    "\n",
    "for i in range(0,n_experiments):\n",
    "    number = random.randint(0, len(tweets_list)-1)\n",
    "    tweet_id = tweets_list[number]\n",
    "    is_in_cache = search_app.tweet_cache.get(tweet_id) is not None\n",
    "    tic = time.perf_counter()\n",
    "    search_app.fetch_tweets_from_mongodb([tweet_id])\n",
    "    toc = time.perf_counter()\n",
    "    if is_in_cache:\n",
    "        time_list_cache.append(toc-tic)\n",
    "    else:\n",
    "        time_list_wo_cache.append(toc-tic)\n",
    "    \n",
    "results = {\n",
    "    'with_cache':time_list_cache,\n",
    "    'without_cache':time_list_wo_cache\n",
    "}\n",
    "\n",
    "with open('tweet_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without cache\n",
      "mean: 15.6105 ms\n",
      "std: 3.8069 ms\n",
      "With cache\n",
      "mean: 0.0022 ms\n",
      "std: 0.0028 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-24 18:31:48,502 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:31:48,505 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:32:48.492165-04:00 (in 59.986345 seconds)\n",
      "2024-04-24 18:31:48,505 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:32:48 EDT)\" (scheduled at 2024-04-24 18:31:48.492165-04:00)\n",
      "2024-04-24 18:31:48,519 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:31:48,532 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:32:48.500163-04:00 (in 59.967185 seconds)\n",
      "2024-04-24 18:31:48,534 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:32:48 EDT)\" (scheduled at 2024-04-24 18:31:48.500163-04:00)\n",
      "2024-04-24 18:31:48,534 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:31:48,557 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:32:48.522608-04:00 (in 59.965091 seconds)\n",
      "2024-04-24 18:31:48,557 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:32:48 EDT)\" executed successfully\n",
      "2024-04-24 18:31:48,557 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:32:48 EDT)\" executed successfully\n",
      "2024-04-24 18:31:48,557 - apscheduler.executors.default - INFO - Running job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:32:48 EDT)\" (scheduled at 2024-04-24 18:31:48.522608-04:00)\n",
      "2024-04-24 18:31:48,561 - apscheduler.executors.default - INFO - Job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:32:48 EDT)\" executed successfully\n",
      "2024-04-24 18:32:48,507 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:32:48,508 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:32:48,508 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:33:48.492165-04:00 (in 59.983327 seconds)\n",
      "2024-04-24 18:32:48,509 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:33:48 EDT)\" (scheduled at 2024-04-24 18:32:48.492165-04:00)\n",
      "2024-04-24 18:32:48,509 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:33:48.500163-04:00 (in 59.990327 seconds)\n",
      "2024-04-24 18:32:48,509 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:33:48 EDT)\" (scheduled at 2024-04-24 18:32:48.500163-04:00)\n",
      "2024-04-24 18:32:48,529 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:33:48 EDT)\" executed successfully\n",
      "2024-04-24 18:32:48,539 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:32:48,549 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:33:48.522608-04:00 (in 59.973147 seconds)\n",
      "2024-04-24 18:32:48,553 - apscheduler.executors.default - INFO - Running job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:33:48 EDT)\" (scheduled at 2024-04-24 18:32:48.522608-04:00)\n",
      "2024-04-24 18:32:48,564 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:33:48 EDT)\" executed successfully\n",
      "2024-04-24 18:32:48,565 - apscheduler.executors.default - INFO - Job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:33:48 EDT)\" executed successfully\n",
      "2024-04-24 18:33:48,498 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:33:48,501 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:34:48.492165-04:00 (in 59.991044 seconds)\n",
      "2024-04-24 18:33:48,501 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:34:48 EDT)\" (scheduled at 2024-04-24 18:33:48.492165-04:00)\n",
      "2024-04-24 18:33:48,513 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:33:48,530 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:34:48.500163-04:00 (in 59.971027 seconds)\n",
      "2024-04-24 18:33:48,533 - apscheduler.executors.default - INFO - Running job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:34:48 EDT)\" (scheduled at 2024-04-24 18:33:48.500163-04:00)\n",
      "2024-04-24 18:33:48,547 - apscheduler.scheduler - DEBUG - Looking for jobs to run\n",
      "2024-04-24 18:33:48,570 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:34:48 EDT)\" executed successfully\n",
      "2024-04-24 18:33:48,578 - apscheduler.executors.default - INFO - Job \"Cache.save_to_disk (trigger: interval[0:01:00], next run at: 2024-04-24 18:34:48 EDT)\" executed successfully\n",
      "2024-04-24 18:33:48,578 - apscheduler.scheduler - DEBUG - Next wakeup is due at 2024-04-24 18:34:48.522608-04:00 (in 59.944448 seconds)\n",
      "2024-04-24 18:33:48,579 - apscheduler.executors.default - INFO - Running job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:34:48 EDT)\" (scheduled at 2024-04-24 18:33:48.522608-04:00)\n",
      "2024-04-24 18:33:48,583 - apscheduler.executors.default - INFO - Job \"TrendingHashtags.save_trending_hashtags (trigger: interval[0:01:00], next run at: 2024-04-24 18:34:48 EDT)\" executed successfully\n"
     ]
    }
   ],
   "source": [
    "time_list_wo_cache = np.array(time_list_wo_cache)\n",
    "chosen_ids = random.sample(range(0,len(time_list_wo_cache)), stats_sample)\n",
    "print('Without cache')    \n",
    "print('mean:',f'{np.mean(time_list_wo_cache[chosen_ids])*1000:0.4f} ms')\n",
    "print('std:',f'{np.std(time_list_wo_cache[chosen_ids])*1000:0.4f} ms')\n",
    "time_list_cache = np.array(time_list_cache)\n",
    "chosen_ids = random.sample(range(0,len(time_list_cache)), stats_sample)\n",
    "print('With cache')  \n",
    "print('mean:',f'{np.mean(time_list_cache[chosen_ids])*1000:0.4f} ms')\n",
    "print('std:',f'{np.std(time_list_cache[chosen_ids])*1000:0.4f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
